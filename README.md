# CraigslistApartmentCrawler
Project to Analyze Portland Apartment pricing data

The flow will work like this:

1. ID numbers will be scraped from the home page,
2. Info will be gathered from indivdual pages
3. Data organizer, will clean up the data that is pulled, and write it to a CSV File

I am struggling now with finding a way to run the program for about a week straight, without having to disconnect my computer. I have looked at AWS and PythonAnywhere. I'm not sure how to set either up.


